\section{Introduction}
We propose a methodology for assigning the earliest calendar year in which a question--answer bundle could likely have been written, and we apply it to produce a large, time-grounded post-training dataset based on Tulu-3.

\paragraph{Task.}
Let $x$ be a text sample.
Let $P_{x,\mathrm{gt}}(t)$ denote the (latent) distribution over earliest times $t$ such that the text could be produced without relying on unavailable or speculative knowledge at time $t$, as judged by a well-informed observer.
Given $x$, predict the $\alpha$-quantile of $P_{x,\mathrm{gt}}$:
\[
t_\alpha(x)
\;=\;
\inf\Bigl\{ t \;:\; \Pr_{T \sim P_{x,\mathrm{gt}}}\!\bigl(T \le t\bigr) \ge \alpha \Bigr\}.
\]

\paragraph{Interpretation.}
A fraction $\alpha$ of informed observers would judge time $t_\alpha(x)$ (or earlier) to be admissible.
Times earlier than $t_\alpha(x)$ lie in the premature tail.

\paragraph{Applications.}
Synchronos LLMs are models trained on data restricted to specific year ranges.
Potential applications include finance backtesting to avoid look-ahead bias, historical analysis with time-bounded knowledge, auditing model behavior under controlled knowledge cutoffs, and reproducible evaluations that fix the temporal scope of training data.
